{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Programmentwurf DataScience\n",
    "\n",
    "Bearbeitet von:\n",
    "- 3256863\n",
    "- 1646552"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- [Programmentwurf DataScience](attachment:./#Programmentwurf-DataScience)\n",
    "  * [1. Business Understanding](attachment:./#1.-Business-Understanding)\n",
    "    * [Ziele des Business Understandings](attachment:./#Ziele-des-Business-Understandings)\n",
    "  * [2. Data Exploration und Analyse](attachment:./#2.-Data-Exploration-und-Analyse)\n",
    "    * [Laden der Test und Trainingsdatensätze](attachment:./#Laden-der-Test-und-Trainingsdatensätze)\n",
    "    * [Histogramm über den Verkaufspreis](attachment:./#Histogramm-über-den-Verkaufspreis)\n",
    "    * [Korrelationsmatrix über alle Features des Datensatzes](attachment:./#Korrelationsmatrix-über-alle-Features-des-Datensatzes)\n",
    "    * [Darstellungen des Zusammenhangs einzelner Attribute mit dem Verkaufspreis](attachment:./#Darstellungen-des-Zusammenhangs-einzelner-Attribute-mit-dem-Verkaufspreis)\n",
    "      * [Boxplot zur Analyse des fehlenden Zusammenhangs zwischen Verkaufspreis und der Anzahl an Zimmern](attachment:./#Boxplot-zur-Analyse-des-fehlenden-Zusammenhangs-zwischen-Verkaufspreis-und-der-Anzahl-an-Zimmern)\n",
    "      * [Einfluss des Baujahrs und des Dachtyps auf den Verkaufspreis](attachment:./#Einfluss-des-Baujahrs-und-des-Dachtyps-auf-den-Verkaufspreis)\n",
    "      * [Einfluss des Umbaujahres auf den Verkaufspreis](attachment:./#Einfluss-des-Umbaujahres-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Erdgeschossfläche auf den Verkaufspreis](attachment:./#Einfluss-der-Erdgeschossfläche-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Kellerfläche auf den Verkaufspreis](attachment:./#Einfluss-der-Kellerfläche-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Wohnfläche auf den Verkaufspreis](attachment:./#Einfluss-der-Wohnfläche-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Grundstücksfläche auf den Verkaufspreis](attachment:./#Einfluss-der-Grundstücksfläche-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Kellerqualität auf den Verkaufspreis](attachment:./#Einfluss-der-Kellerqualität-auf-den-Verkaufspreis)\n",
    "      * [Einfluss des Verkaufsjahrs auf den Verkaufspreis](attachment:./#Einfluss-des-Verkaufsjahrs-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Anzahl an Bädern auf den Verkaufspreis](attachment:./#Einfluss-der-Anzahl-an-Bädern-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Anzahl an Bädern im UG auf den Verkaufspreis](attachment:./#Einfluss-der-Anzahl-an-Bädern-im-UG-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Anzahl an Kaminen auf den Verkaufspreis](attachment:./#Einfluss-der-Anzahl-an-Kaminen-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Lage auf den Verkaufspreis](attachment:./#Einfluss-der-Lage-auf-den-Verkaufspreis)\n",
    "      * [Einfluss des Haustyp auf den Verkaufspreis](attachment:./#Einfluss-des-Haustyp-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Anzahl an Garagen auf den Verkaufspreis](attachment:./#Einfluss-der-Anzahl-an-Garagen-auf-den-Verkaufspreis)\n",
    "      * [Einfluss des Gesamteindrucks auf den Verkaufspreis](attachment:./#Einfluss-des-Gesamteindrucks-auf-den-Verkaufspreis)\n",
    "      * [Einfluss des Verkaufsmonats auf den Verkaufspreis](attachment:./#Einfluss-des-Verkaufsmonats-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Anzahl an Toiletten auf den Verkaufspreis](attachment:./#Einfluss-der-Anzahl-an-Toiletten-auf-den-Verkaufspreis)\n",
    "      * [Einfluss der Ausbaustufe auf den Verkaufspreis](attachment:./#Einfluss-der-Ausbaustufe-auf-den-Verkaufspreis)\n",
    "    * [Zusammenfassung der Erkenntnisse](attachment:./#Zusammenfassung-der-Erkenntnisse)\n",
    "      * [Rückfragen für Fachexperte (z.B. Immobilienmakler, Architekten) und weitere Datenquellen:](attachment:./#Rückfragen-für-Fachexperte-(z.B.-Immobilienmakler,-Architekten)-und-weitere-Datenquellen:)\n",
    "  * [3. Data Preparation](attachment:./#3.-Data-Preparation)\n",
    "    * [Feature Engineering](attachment:./#Feature-Engineering)\n",
    "      * [Ausbaustufe: Intervallskala](attachment:./#Ausbaustufe:-Intervallskala)\n",
    "      * [Bebauungsdichte: Ordinalskala](attachment:./#Bebauungsdichte:-Ordinalskala)\n",
    "      * [Besonderheiten: Nominalskala mit vielen Nullwerten](attachment:./#Besonderheiten:-Nominalskala-mit-vielen-Nullwerten)\n",
    "      * [Dachtyp](attachment:./#Dachtyp)\n",
    "      * [Fassadenqualität](attachment:./#Fassadenqualität)\n",
    "      * [Fasadenzustand](attachment:./#Fasadenzustand)\n",
    "      * [Kellerhoehe](attachment:./#Kellerhoehe)\n",
    "      * [Lage](attachment:./#Lage)\n",
    "      * [Typ](attachment:./#Typ)\n",
    "    * [Datenbereinigung](attachment:./#Datenbereinigung)\n",
    "      * [Anzahl Zimmer](attachment:./#Anzahl-Zimmer)\n",
    "      * [Ausbaustufe](attachment:./#Ausbaustufe)\n",
    "      * [Baeder](attachment:./#Baeder)\n",
    "      * [BaederUG](attachment:./#BaederUG)\n",
    "      * [Baujahr](attachment:./#Baujahr)\n",
    "      * [Bebauungsdichte](attachment:./#Bebauungsdichte)\n",
    "      * [Dachtyp](attachment:./#Dachtyp)\n",
    "      * [EG_qm](attachment:./#EG_qm)\n",
    "      * [Fassadenqualität](attachment:./#Fassadenqualität)\n",
    "      * [Fassadenzustand](attachment:./#Fassadenzustand)\n",
    "      * [Garagen](attachment:./#Garagen)\n",
    "      * [Gesamteindruck](attachment:./#Gesamteindruck)\n",
    "      * [Grundstueck_qm](attachment:./#Grundstueck_qm)\n",
    "      * [Kamine](attachment:./#Kamine)\n",
    "      * [KellerQual](attachment:./#KellerQual)\n",
    "      * [Keller_qm](attachment:./#Keller_qm)\n",
    "      * [Kellerhöhe](attachment:./#Kellerhöhe)\n",
    "      * [Lage](attachment:./#Lage)\n",
    "      * [ToilettenEG](attachment:./#ToilettenEG)\n",
    "      * [ToilettenUG](attachment:./#ToilettenUG)\n",
    "      * [Typ](attachment:./#Typ)\n",
    "      * [Umgebaut](attachment:./#Umgebaut)\n",
    "      * [Verkaufsjahr](attachment:./#Verkaufsjahr)\n",
    "      * [Verkaufsmonat](attachment:./#Verkaufsmonat)\n",
    "      * [Wohnflaeche_qm](attachment:./#Wohnflaeche_qm)\n",
    "      * [Seelage](attachment:./#Seelage)\n",
    "      * [Neuverkauf](attachment:./#Neuverkauf)\n",
    "    * [Korrelationsmatrix nach der Aufbereitung und Bereinigung des Datensatzes](attachment:./#Korrelationsmatrix-nach-der-Aufbereitung-und-Bereinigung-des-Datensatzes)\n",
    "  * [4. Modeling - Regression mit Interferenz](attachment:./#4.-Modeling---Regression-mit-Interferenz)\n",
    "    * [Protokoll über die vorgenommenen Änderungen](attachment:./#Protokoll-über-die-vorgenommenen-Änderungen)\n",
    "    * [Cross-Validierung](attachment:./#Cross-Validierung)\n",
    "    * [R²-Wert mit zugehörigen Features](attachment:./#R²-Wert-mit-zugehörigen-Features)\n",
    "    * [Linear Regression](attachment:./#Linear-Regression)\n",
    "    * [Linear Regression mit reduzierten Attributen](attachment:./#Linear-Regression-mit-reduzierten-Attributen)\n",
    "    * [Lasso Regression](attachment:./#Lasso-Regression)\n",
    "    * [Ridge Regression](attachment:./#Ridge-Regression)\n",
    "  * [5. Modeling - Best of Class](attachment:./#5.-Modeling---Best-of-Class)\n",
    "    * [Hinweis](attachment:./#Hinweis)\n",
    "    * [Random Forest](attachment:./#Random-Forest)\n",
    "    * [Gradient Boosted Tree](attachment:./#Gradient-Boosted-Tree)\n",
    "    * [Passive Agressive Regressor](attachment:./#Passive-Agressive-Regressor)\n",
    "    * [Linear Support Vector Regressor](attachment:./#Linear-Support-Vector-Regressor)\n",
    "    * [Grid Search für Gradient Boosted Tree](attachment:./#Grid-Search-für-Gradient-Boosted-Tree)\n",
    "      * [Erste Iteration](attachment:./#Erste-Iteration)\n",
    "      * [Zweite Iteration](attachment:./#Zweite-Iteration)\n",
    "      * [Dritte Iteration](attachment:./#Dritte-Iteration)\n",
    "      * [Finale Hyperparameter](attachment:./#Finale-Hyperparameter)\n",
    "  * [6. Evaluation und Test](attachment:./#6.-Evaluation-und-Test)\n",
    "    * [Trick 17: Finales Trainieren des Modells auf den gesamten Daten mit ausgewählten Hyperparametern](attachment:./#Trick-17:-Finales-Trainieren-des-Modells-auf-den-gesamten-Daten-mit-ausgewählten-Hyperparametern)\n",
    "  * [7. Deployment](attachment:./#7.-Deployment)\n",
    "  * [Anleitung für den Immobilienverein](attachment:./#Anleitung-für-den-Immobilienverein)\n",
    "    * [Verkaufspreisvorhersage](attachment:./#Verkaufspreisvorhersage)\n",
    "    * [Steigerung des Wertes eines Hauses](attachment:./#Steigerung-des-Wertes-eines-Hauses)\n",
    "    * [Wichtigste Erkenntnisse:](attachment:./#Wichtigste-Erkenntnisse:)\n",
    "    * [Augen auf beim Häuserkauf!](attachment:./#Augen-auf-beim-Häuserkauf!)\n",
    "  * [Add-On: Modeling - Klassifikation](attachment:./#Add-On:-Modeling---Klassifikation)\n",
    "    * [Funktion für die Berechnung von Klassifikationsmetriken mithilfe von 5 Fold CV](attachment:./#Funktion-für-die-Berechnung-von-Klassifikationsmetriken-mithilfe-von-5-Fold-CV)\n",
    "    * [Logistische Regression](attachment:./#Logistische-Regression)\n",
    "    * [Gradient Boosting Classifier](attachment:./#Gradient-Boosting-Classifier)\n",
    "    * [Random Forest Classifier](attachment:./#Random-Forest-Classifier)\n",
    "    * [Support Vector Classification](attachment:./#Support-Vector-Classification)\n",
    "    * [K Nearest Neighbours](attachment:./#K-Nearest-Neighbours)\n",
    "    * [Naives Bayes Classificator](attachment:./#Naives-Bayes-Classificator)\n",
    "    * [Vergleich der Klassifikationsmethoden](attachment:./#Vergleich-der-Klassifikationsmethoden)\n",
    "  * [Evaluation](attachment:./#Evaluation)\n",
    "  * [Bewertungskriterien](attachment:./#Bewertungskriterien)"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Business Understanding\n",
    "**Aufgabenstellung**: _Formulieren Sie ein Ziel oder mehrere Ziele nach dem CRISP-DM Prozess, die für __einen Immobilienverein von Privatpersonen__ sinnvoll sind. Diese Personen kaufen und verkaufen Häuser zur Eigennutzung oder für die Familie, manchmal mehrfach. Beginnen Sie mit der Idee „Wir brauchen mehr Verständnis und eine Vorhersage des Verkaufspreises (`Z_Verkaufspreis`)!“, welche auf jeden Fall zu bearbeiten ist. Geben Sie dies in Ihrem Jupyter-Notebook als Markup an (max. ½ Seite Text)._\n",
    "\n",
    "### Ziele des Business Understandings\n",
    "- Was sind die Ziele auf Geschäftsebene?\n",
    "- Welche Anforderungen an das Ergebnis gibt es?\n",
    "- Welche offenen Fragen sollen beantwortet werden?\n",
    "- Wie könnten beispielhafte Antworten aussehen?\n",
    "\n",
    "Das grundsätzliche Ziel ist die Evaluation der Rechtfertigkeit eines Hauspreises. Es soll vermieden werden, Häuser zu teuer anzukaufen, beziehungsweise zu billig zu verkaufen.\n",
    "Das Ergebnis der Datenanalyse soll eine verlässlige Vorhersage eines Hauspreises aufgrund gegebener Attribute liefern. Dadurch ergeben sich die Fragen:\n",
    "1. Durch welche Attribute wird der Preis eines Hauses festgemacht?\n",
    "2. Wie stark beeinflusst ein Attribut den Preis?\n",
    "3. Gibt es eine Möglichkeit den Wert eines Hauses vergleichsweise einfach zu steigern? Sprich welche Investitionen beeinflussen den Hauspreis positiv und sind gleichzeitig vergleichsweise billig. Diese Möglichkeiten sollen auch bei einem Kaufvorschlag in Betracht gezogen werden.\n",
    "\n",
    "Außerdem soll das Verfahren eine einfache Möglichkeit liefern, einen Hauspreis aufgrund von gegebenen Informationen schätzen zu können. Diese Schätzung soll auch ohne Kenntnisse in DataScience möglich sein, beispielsweise durch eine Formel. Diese Formel wird durch die Vorhersage des Programms bestimmt und sollte möglichst universell einsetzbar sein. Ein Beispiel für eine Formel wäre `Grundfläche * 1000 + AnzahlZimmer * 10 000 + ...`. Die Formel besteht aus den wichtigsten Attributen (Fragestellungen 1. und 2. von oben) und einem statischen Faktor.\n",
    "\n",
    "Zusätzlich soll der Datenbestand als Grundlage für eine Anwendung dienen, in welche die Eigenschaften und der Preis des Hauses eingetragen werden können. Diese Anwendung führt eine Kategorisierung in \"Direkt kaufen\", \"Abwarten\" und \"Schlechtes Angebot\" durch. Dadurch soll der Aufwand für die Privatpersonen reduziert und bei der Entscheidungsfindung geholfen werden.\n",
    "\n",
    "Neben der Vorhersage und Abhängigkeit des Preises von Attributen sollen auch Zusammenhänge der Attribute untereinander gefunden werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data Exploration und Analyse\n",
    "**Aufgabenstellung**: _Laden und untersuchen Sie den Datensatz in data_for_training.csv nach den Regeln wie in der Vorlesung gelehrt. Ändern Sie hierbei nicht die einzulesende csv-Datei! Schreiben Sie die wichtigsten Erkenntnisse für die in Aufgabe 1 definierten Ziele als Summary auf (max. ½ Seite Text). Passen Sie ggfs. Ihre Ziele im Business Understanding an. Kommentieren Sie Rückfragen für Fachexperten sowie mögliche zusätzliche Datenquellen und Auswertungen, die Sie damit ausführen würden._"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Laden der Test und Trainingsdatensätze"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Importieren der Bibliotheken\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ],
   "execution_count": 1,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Einlesen der Trainingsdaten\n",
    "train_data = pd.read_csv('data_for_training.csv', delimiter=\";\").drop(columns=\"A_Index\")"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_for_training.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9100/1957414745.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Einlesen der Trainingsdaten\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtrain_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'data_for_training.csv'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\";\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcolumns\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"A_Index\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    481\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 482\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    483\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    484\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    810\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 811\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    812\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1038\u001B[0m             )\n\u001B[0;32m   1039\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1040\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1041\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1042\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    221\u001B[0m         \"\"\"\n\u001B[1;32m--> 222\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Data Science\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    700\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;34m\"b\"\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    701\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 702\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data_for_training.csv'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anzeigen der Trainingsdaten\n",
    "train_data"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anzeigen einer Scatterplotmatrix über ausgewählte Attribute\n",
    "_ = sns.pairplot(train_data.loc[:, [\"Baujahr\", \"EG_qm\", \"Grundstueck_qm\", \"Keller_qm\", \"Umgebaut\", \"Wohnflaeche_qm\"]])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Diese Scatterplotmatrix verdeutlicht vor allem die Zusammenhänge von Attributen zueinander.\n",
    "\n",
    "Die Histogramme auf der Diagonale zeigen:\n",
    "- Ein Großteil der Häuser wurde in den letzten zwei Jahrzehnten erbaut.\n",
    "- Die Flächen (_EG_qm_, _Grundstueck_qm_, _Keller_qm_ und _Wohnflaeche_qm_) sind normalverteilt, aber leicht verschoben.\n",
    "- 1960 wurden überraschend viele Häuser umgebaut. Dies könnte vermutlich den frühest möglichen Wert für *Umgebaut* darstellen.\n",
    "\n",
    "Die Deckelung (Dachform) zwischen _Umgebaut_ und _Baujahr_ stellt all die Häuser dar, die noch nicht umgebaut wurden. Auch lässt sich erkennen, dass ein Großteil der Häuser nach der Jahrtausendwende umgebaut wurden.\n",
    "\n",
    "In _Keller_qm_ und _EG_qm_ lässt sich ein aufsteigender Trend über die Jahre beobachten (_Baujahr_). Dieser Trend ist bei _Wohnflaeche_qm_ allerdings nicht sichtbar.\n",
    "\n",
    "Die Winkelhalbierende zwischen _EG_qm_ und _Wohnflaeche_qm_ repräsentiert diejenigen Häuser, die nur aus einem Erdgeschoss bestehen.\n",
    "\n",
    "Jedes Haus mit mehr als 200 m² Erdgeschoss besitzt einen Keller.\n",
    "\n",
    "Die beiden Ausreißer in _Grundstueck_qm_ liegen in fast allen anderen Attributen ebenfalls eng beeinander mit der Ausnahme, dass eines der beiden Häuser renoviert wurde. Gleiches gilt für _Keller_qm_ und _EG_qm_. Auch hier sind die Ausreißer oft beeinander."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Histogramm über den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anlegen eines Graphen und befüllen mit Histogrammdaten\n",
    "_, axes = plt.subplots(figsize=(15, 10))\n",
    "axes.set_title(\"Histogramm über den Verkaufspreis\")\n",
    "axes.set_xlabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_ylabel(\"Anzahl der Häuser\")\n",
    "_ = train_data[\"Z_Verkaufspreis\"].hist(bins=100, ax=axes)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Ausgeben der Kennwerte des Verkaufspreises\n",
    "train_data[\"Z_Verkaufspreis\"].describe()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Das Histogramm über den Verkaufspreis und die Datensatzbeschreibung zeigen, dass ein Großteil der Häuser in der Preisspanne zwischen 100 000€ und 300 000€ verkauft werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Korrelationsmatrix über alle Features des Datensatzes\n",
    "Hierbei werden nur numerische Features berechnet, alle anderen müssen noch codiert werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Definieren einer Maske, die alle Werte in dem oberen Dreieck auf 0 setzt\n",
    "mask = np.triu(np.ones_like(train_data.corr(), dtype=bool))\n",
    "\n",
    "# Darstellen der Korrelations-Heatmap\n",
    "heatmap = sns.heatmap(train_data.corr(), mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize': 18}, pad=16);"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Korrelationsmatrix zeigt, dass der Verkaufspreis (_Z_Verkaufspreis_) von vielen Attributen abhängig ist.\n",
    "\n",
    "Neben der Wohnfläche (_Wohnfläche_qm_, bestehend aus _EQ_qm_ und _Keller_qm_) korreliert die Anzahl der Garagen überraschend hoch mit dem Verkaufspreis. Außerdem korrelieren die Anzahl der Bäder (_Baeder_), das _Baujahr_ (zusammen mit _Umgebaut_) und die Anzahl der Kamine (_Kamine_) positiv mit dem Verkaufspreis.\n",
    "Entgegen der Erwartungen spielt die Anzahl der Zimmer eine eher kleine Rolle in der Bestimmung des Verkaufspreises. Auch die Gesamtfläche des Grundstückes spielt eine eher zu vernachlässigende Rolle mit einer Korrelation von 0,26.\n",
    "\n",
    "Die größte Korrelation tritt zwischen _Keller_qm_ und _EG_qm_ auf, was sich durch den baulich bedingten Zusammenhang zwischen Keller und Erdgeschoss erklären lässt.\n",
    "\n",
    "Die Korrelation von Verkaufsjahr und Verkaufspreis kann durch die steigenden Immobilienpreise und die zusätzliche Inflation erklärt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Darstellungen des Zusammenhangs einzelner Attribute mit dem Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Aussortieren der Attribute mit nicht kontinuierlichen Werten\n",
    "train_data_without_objects = train_data.select_dtypes(exclude=['object'])\n",
    "prices = train_data_without_objects[\"Z_Verkaufspreis\"]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Boxplot zur Analyse des fehlenden Zusammenhangs zwischen Verkaufspreis und der Anzahl an Zimmern"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Relevante Spalten auswählen\n",
    "selection = train_data_without_objects.loc[:, [\"Z_Verkaufspreis\", \"AnzahlZimmer\"]]\n",
    "\n",
    "# Graph anlegen, beschreiben und mit Boxplot füllen\n",
    "plt.figure(figsize=(20, 10))\n",
    "axes = sns.boxplot(x=\"AnzahlZimmer\", y=\"Z_Verkaufspreis\", data=train_data, color=\"blue\")\n",
    "axes.set_title(\"Violinplot über den Verkaufspreis abhängig von der Anzahl an Zimmern\")\n",
    "axes.set_xlabel(\"Anzahl der Zimmer\")\n",
    "_ = axes.set_ylabel(\"Verkaufspreis in Euro\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie bereits in der Korrelationsmatrix erkannt, ist der Zusammenhang zwischen Verkaufspreis und der Anzahl an Zimmern sehr gering.\n",
    "\n",
    "Normalerweise würde man hier eine stetige Steigerung des Verkaufspreises erwarten, je mehr Zimmer in dem Haus vorhanden sind. Dem ist aber nicht so. Häuser mit zwei Zimmern kosten im Durchschnitt ähnlich viel wie Häuser mit sechs Zimmer.\n",
    "Da nur ein Haus mit acht Zimmern vorhanden ist, lässt sich dieser Wert vernachlässigen.\n",
    "\n",
    "Für die Datensätze mit einer representativen Anzahl n=2,3,4 gibt es einen geringen Anstieg des Median und des unteren Quartils.\n",
    "\n",
    "Ausreiser/Extreme:\n",
    "|Anzahl Zimmer|Anzahl Datensätze|Anmerkung\n",
    "|:-----------:|:---------------:|---------\n",
    "|0            | 6               | Ausreiser, nicht möglich\n",
    "|5            | 32              |\n",
    "|6            | 16              |\n",
    "|8            | 1               |"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Baujahrs und des Dachtyps auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Erstellen eines Scatterplots über Baujahr und Verkaufspreis\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"Einfluss des Baujahrs und des Dachtyps auf den Verkaufspreis\")\n",
    "plt.ylabel(\"Verkaufspreis in Euro\")\n",
    "_ = sns.scatterplot(data=train_data, x=\"Baujahr\", y=\"Z_Verkaufspreis\", hue=\"Dachtyp\")  # Scatterplot wird nach Dachtyp eingefärbt"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier lässt sich gut erkennen, dass neuere Häuser tendenziell einen höheren Verkaufspreis haben als ältere.\n",
    "Durch die Einfärbung abhängig von dem Dachtyp lassen sich die verschiedenen Trends im Häuserbau erkennen. Das Satteldach ist über die gesamte Periode präsent, während Häuser mit Walmdach fast nur vor 1920 gebaut wurden. Das selbe trifft auch für Mansarddächer zu, diese wurden primär vor 1940 gebaut. Ab 1960 haben Häuser fast nur noch Flach- oder Satteldächer. Fast alle Häuser mit einem sehr hohen Verkaufspreis (> 500 000 €) haben Flachdächer und wurden nach 2000 gebaut."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Spalten, die numerische Werte enthalten\n",
    "numeric_columns = [\"Baujahr\", \"EG_qm\", \"Grundstueck_qm\", \"Keller_qm\", \"Umgebaut\", \"Wohnflaeche_qm\"]\n",
    "numerical_data = train_data_without_objects.loc[:, numeric_columns]\n",
    "\n",
    "\n",
    "def show_scatter(columnName, drop=None):\n",
    "    \"\"\"\n",
    "    Zeigt einen Scatterplot zum Vergleichen des Zusammenhangs der gegebenen Spalte mit dem Verkaufspreis.\n",
    "    Zusätzlich kann angegeben werden, ob bestimmte Werte in der Darstellung nicht berücksichtigt werden sollen.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Erstellen des Scatterplots\n",
    "    if drop is None:\n",
    "        column_compare = train_data_without_objects[columnName]\n",
    "        plt.scatter(column_compare, prices)\n",
    "    else:\n",
    "        # Entfernen der Datensätze, sofern gewünscht\n",
    "        column_compare = train_data_without_objects[columnName].drop(drop)\n",
    "        plt.scatter(column_compare, prices.drop(drop))\n",
    "\n",
    "    # Beschriftungen hinzufügen und anzeigen\n",
    "    plt.title(f\"Verkaufspreis vs. {columnName}\")\n",
    "    plt.xlabel(columnName)\n",
    "    plt.ylabel(\"Verkaufspreis in Euro\")\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Umbaujahres auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Umgebaut\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dieser Scatterplot ähnelt dem obigen über das Baujahr stark und verdeutlicht den Zusammenhang zwischen Verkaufspreis und dem Jahr noch deutlicher. Häuser, die im obigen Graphen herausstechen (z. B. 450 000 € bei Baujahr 1900) sind im _Umgebaut_-Plot nicht mehr vorhanden. Daraus lässt sich schließen, dass der Umbau (/Renovierung) den Wert eines Hauses steigert. Außerdem wird die Vermutung \"Neuere Häuser sind teurer\" auch für alte, aber renovierte, Häuser wahr."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Erdgeschossfläche auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"EG_qm\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die starke Korrelation zwischen _EG_qm_ und _Z_Verkaufspreis_ aus der obigen Korrelationmatrix wird durch diesen Scatterplot verdeutlicht. Entfernt man die Ausreißer bei EG_qm > 400, ergibt sich der folgende Plot:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"EG_qm\", [737, 216])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Kellerfläche auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Keller_qm\", [216, 737])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hier wurden zwei Ausreißer bereits entfernt. Bei den Ausreißern handelt es sich um die selben wie bei _EG_qm_**\n",
    "\n",
    "Dieser Plot ist nahezu deckungsgleich mit dem Plot über _EG_qm_. Da beide Attribute eine Korrelation von 0,81 haben, ist das keine Überraschung. Allerdings stechen die Einträge bei 0 m² Kellerfläche ins Auge. Möglich wäre, dass es sich hierbei um Häuser ohne Keller handelt, oder eben Ausreißer. "
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Wohnfläche auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Wohnflaeche_qm\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Da sich die Wohnfläche unter anderem aus _EG_qm_ und _Keller_qm_ zusammensetzt, ist hier ein ähnlicher Zusammenhang zum Verkaufspreis zu erkennen. Je mehr Wohnfläche ein Haus bietet, desto teurer kann es verkauft werden. Die drei Ausreißer in der rechten unteren Ecke sind den Ausreißern in _EG_qm_ und _Keller_qm_ geschuldet. Entfernt man die beiden Ausreißer und einen weiteren, sieht der Plot wie folgt aus:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Wohnflaeche_qm\", [737, 216] + [543])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Grundstücksfläche auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Grundstueck_qm\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auch hier stechen die Ausreißer bei 16 000 m² Grundstück ins Auge. Ohne diese beiden Ausreißer wirkt der Zusammenhang zwischen Preis und Grundfläche stärker, allerdings gibt es noch sehr viele große Grundstücke mit einem vergleichsweise niedrigen Preis:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_scatter(\"Grundstueck_qm\", [757, 536])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def show_boxplot(columnName, title_name, x_label=None, rotateLabels=False, data=train_data):\n",
    "    \"\"\"\n",
    "    Zeigt einen Boxplot über Verkaufspreis und gegebener Spalte an.\n",
    "    Der Titel wird durch den gegebenen, grammatikalisch korrekten Satzbaustein gebildet.\n",
    "    Zusätzlich kann noch die Bezeichnung des X-Labels verändert und/oder rotiert werden.\n",
    "    Außerdem kann der Datensatz geändert werden, sofern gewünscht\n",
    "    \"\"\"\n",
    "\n",
    "    _, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    # Generieren des Boxplots\n",
    "    axes = sns.boxplot(x=columnName, y=\"Z_Verkaufspreis\", data=data, color=\"blue\")\n",
    "    \n",
    "    # Titel festlegen\n",
    "    axes.set_title(f\"Einfluss {title_name} auf den Verkaufspreis\")\n",
    "\n",
    "    # Achsenbeschriftungen\n",
    "    if x_label is None:\n",
    "        # Standardbeschriftung\n",
    "        axes.set_xlabel(columnName)\n",
    "    else:\n",
    "        # Besondere Beschriftung\n",
    "        axes.set_xlabel(x_label)\n",
    "    \n",
    "    # Rotieren um 45°, falls gewünscht\n",
    "    if rotateLabels:\n",
    "        axes.set_xticklabels(axes.get_xticklabels(), rotation=45)  # X-label rotieren, um Lesbarkeit zu gewährleisten\n",
    "\n",
    "    axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Kellerqualität auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"KellerQual\", \"der Kellerqualität\", \"Keller Qualität (1:Sehr Schlecht, 2:Schlecht, 3:Durchschnitt, 4:Gut, 5:Sehr Gut)\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es ist kein wesentlicher Zusammenhang der Kellerqualität und des Verkaufpreises ersichtlich."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Verkaufsjahrs auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Verkaufsjahr\", \"des Verkaufsjahres\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier ist ein leichter Aufwärtstrend zu erkennen, Häuser die später verkauft wurden, wurden in der Regel etwas teurer verkauft. Dies hängt sehr wahrscheinlich mit allgemein steigenden Hauspreisen und/oder der Inflation zusammen. Dies kann mit einer Rückfrage an eine Fachkraft geklärt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Anzahl an Bädern auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Baeder\", \"der Anzahl an Bädern\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier ist zu beachten, dass null Bäder nur 10 Datensätze haben, wobei es sich um Fehler handeln könnte, da Häuser typischerweise ein Bad haben. Ebenfalls haben nur vier Datensätze vier Bäder, was auch nicht sehr aussagekräftig ist. Bei den Anzahlen eins bis drei Bädern ist jedoch ein starker Anstieg des Verkaufspreises mit der Anzahl an Bädern zu erkennen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Anzahl an Bädern im UG auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"BaederUG\", \"der Anzahl an Bädern im UG\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Insgesamt ist ein starker Zusammenhang zwischen der Anzahl an Bädern im UG und dem Verkaufspreis zu erkennen, jedoch nicht so stark bei bei der insgesamten Anzahl an Bädern. Dies liegt daran, dass die Gesamtanzahl der Bäder die Bäder im UG auch beinhaltet, für eine Vorhersage sollte die insgesamte Anzahl an Bädern verwendet werden. Eine gleichzeitige Betrachtung beider Features bringt Redundanz."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Anzahl an Kaminen auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Kamine\", \"der Anzahl an Kaminen\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bei der Anzahl an Kaminen ist ein sehr starken Zusammenhang mit dem Verkaufpreis zu erkennen. Dies lässt sich damit erklären, dass Häuser mit vielen Kaminen grundsätzlich größer sind. Für vier Kamine existiert nur ein einzelner Datensatz."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Lage auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Lage\", \"der Lage\", rotateLabels=True)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aus dem Boxplot lässt sich entnehmen, dass Häuser in Neu Stuttgart Süd und West am teuersten verkauft werden. Neu Stuttgart Nord und Ost weisen diese Besonderheit nicht auf."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Haustypen auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Typ\", \"des Haustypen\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Der Typ des Hauses hat keinen Einfluss auf den Verkaufspreis. Zwar sind die Ausreißer nach oben bei freistehenden Häusern prominent, aber der Median liegt trotzdem in einem ähnlichen Bereich wie bei Reihenhäusern. Nur Doppelhaushälften werden im Schnitt zu einem geringeren Preis verkauft."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Anzahl an Garagen auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Garagen\", \"der Anzahl an Garagen\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier ist zu erkennen, dass ein Haus mit einer Garage nur eine geringe Wertsteigerung im Vergleich zu einem Haus mit keiner Garage erfährt. Jedoch ist ein Haus mit zwei Garagen im Median ca. 50k mehr Wert als ein Haus mit einer Garage. Ein Haus mit drei Garagen ist im Median sogar 100k mehr Wert als ein Haus mit zwei Garagen. Für vier Garagen gibt es nur 13 Datensätze, was wenig aussagekräftig ist."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Gesamteindrucks auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Gesamteindruck\", \"des Gesamteindrucks\", \"Gesamteindruck (1:geringster, 5:bester)\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier ist zu beobachten, dass der Preis im Median umso höher liegt, je höher der Gesamteindruck. Gleichzeitig ist aber auch die Preisspanne noch oben deutlich höher (Oberes Quartil und Whisker), bei einem sehr guten Gesamteindruck. Dies ist vor allem herrausstechend für den Gesamteindruck 4. Jedoch erhöht sich die untere Preisspanne (unteres Quartil) nicht so stark mit steigendem Gesamteindruck. Es könnte der Fall sein, dass der Gesamteindruck den möglichen Verhandlungspreis in die Höhe treibt, dieser wird aber nicht immer voll ausgereizt.\n",
    "\n",
    "Ausreiser/Extreme:\n",
    "\n",
    "* Bei Gesamteindruck 0: Es existieren drei Messwerte, der Wert Null ist jedoch nicht in der Skala definiert\n",
    "* Bei Gesamteindruck 5: Hier existieren nur zwei Datensätze, es handelt sich also um eine sehr geringe Sample size."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss des Verkaufsmonats auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Verkaufsmonat\", \"des Verkaufsmonat\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es gibt keinen starken Zusammenhang zwischen Verkaufsmonat und Verkaufspreis. Jedoch wird ersichtlich, dass im Median Häuser am teuersten im Januar verkauft werden. Außerdem gibt es in den Sommermonaten Mai bis Juli die meisten Ausreiser, wovon man ausgehen kann, dass in diesen Monaten eher sehr hochpreisige Häuser verkauft werden. \n",
    "\n",
    "Es kann aber auch daher kommen, dass im Übergang zwischen Frühling und Sommer deutlich mehr Häuser verkauft werden, als in den anderen Monaten. Dies kann dem folgenden Histogramm entnommen werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Generieren des Histogramms\n",
    "train_data[\"Verkaufsmonat\"].hist(bins=12)\n",
    "\n",
    "# Titel und Achsenbeschriftungen\n",
    "axes.set_title(\"Anzahl der Häuser pro Verkaufsmonat\")\n",
    "axes.set_xlabel(\"Verkaufsmonat\")\n",
    "_ = axes.set_ylabel(\"Anzahl der Häuser\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Anzahl an Toiletten auf den Verkaufspreis\n",
    "\n",
    "Hier wird ein neues Feature *Toiletten* erstellt mit:\n",
    "\n",
    "$Toiletten = ToilettenEG + ToilettenUG$"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Korrelation von Verkaufspreis mit ToilettenEg/ ToilettenUG\n",
    "eg_corr = train_data[\"ToilettenEG\"].corr(train_data[\"Z_Verkaufspreis\"])\n",
    "ug_corr = train_data[\"ToilettenUG\"].corr(train_data[\"Z_Verkaufspreis\"])\n",
    "\n",
    "print(\"Korrelation mit Z_Verkaufspreis:\")\n",
    "print(f\"\\t- ToilettenEG: {np.round(eg_corr, 3)}\")\n",
    "print(f\"\\t- ToilettenUG: {np.round(ug_corr, 3)}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Erstellen des neuen Features \n",
    "train_data[\"Toiletten\"] = train_data[\"ToilettenEG\"] + train_data[\"ToilettenUG\"]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Neue Korrelation zwischen: Toiletten, Verkaufspreis: {train_data['Toiletten'].corr(train_data['Z_Verkaufspreis'])}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Kombination der Features ToilettenEG und ToilettenUG bringt keine Verbesserung für die Korrelation mit dem Verkaufspreis im Vergleich zu ToilettenEG, sogar eine Verschlechterung."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"ToilettenEG\", \"der Anzahl an Toiletten im EG\", \"Toiletten im EG\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es ist ein leichter Ansteig des Verkaufspreises anhand der Anzahl an Toiletten im EG zu erkennen.\n",
    "\n",
    "Anzahl Datensätze mit zwei Toiletten im EG: 17"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Einfluss der Ausbaustufe auf den Verkaufspreis"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Ausbaustufe\", \"der Ausbaustufe\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scheinbar gibt es keinen wesentlichen Zusammenhang zwischen der Ausbaustufe und dem Verkaufspreis."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Zusammenfassung der Erkenntnisse\n",
    "\n",
    "Allgemein liegen 50% der Häuser in der Preisspanne von 134 344 € bis 226 935 € mit einem durchschnittlichen Preis von 191 351 €.\n",
    "\n",
    "Insgesamt wurde durch die Einzelplots die Aussage der Korrelationsmatrix über kontinuierliche Werte bestätigt: Der Hauspreis setzt sich primär (Korrelation von über 0.5, absteigend sortiert) aus **_Fassadenqualität, Wohnflaeche_qm, Kellerhöhe, Garagen, Keller_qm, EG_qm, Baujahr, Baeder_** und **_Umgebaut_** zusammen. Auch relevant (0.2 < Korrelation < 0.5, absteigend sortiert) sind: _Kamine, Gesamteindruck, BaederUG, ToilettenEG_ und _Grundstueck_qm_. \n",
    "\n",
    "Insgesamt sind Häuser im Stadtteil NeuStuttgart (_NeuStuttgart_West_ und _NeuStuttgart_Sued_) am teuersten. Alle anderen Stadtteile bewegen sich in ähnlichen Preisspannen.\n",
    "\n",
    "Entgegen der Intuition spielt die Anzahl der Zimmer eine geringe Rolle für den Verkaufspreis.\n",
    "\n",
    "Eine Erkenntnis aus dem Label-Encoding ist, dass der Dachtyp den Preis eines Hauses negativ beeinflussen kann. Dies hängt von den aktuellen Trends zum Bauzeitpunkt des Hauses ab. Ein neues Haus mit Satteldach kostet beispielsweise um einiges mehr als ein Haus aus den 1940er mit einem Mansarddach. Diese These lässt sich durch Rückfragen an Architekturexperten aufdecken.\n",
    "\n",
    "Eine Möglichkeit, den Verkaufswert des Hauses durch eine (relativ kleine) Investition zu steigern, wäre eine Renovierung der Fassade. Diese ist - zusammen mit der Wohnfläche - das Feature, welches den größten Einfluss auf den Preis hat. Für alle anderen Features, die einen starken Zusammenhang mit dem Verkaufpreis haben, wären teurere Investitionen (wie z.B. der Bau einer Garage) nötig, oder sie wären unpraktikabel (z.B. Vergrößerung der Kellerhöhe).\n",
    "\n",
    "\n",
    "#### Rückfragen für Fachexperte (z.B. Immobilienmakler, Architekten) und weitere Datenquellen:\n",
    "\n",
    "* Warum werden im Sommer mehr Häuser verkauft ?\n",
    "* Wie lange dauert es durchschnittlich, bis ein Haus renoviert wird ?\n",
    "* Welche Trendperioden gab es im Häuserbau ? Dokumentation über die prägenden Merkmale einer solchen Phase (Dachtyp, etc.) als mögliche Datenquelle.\n",
    "* Datenquelle mit Einträgen über das durchschnittliche Einkommen in den jeweiligen Stadtteilen. Damit kann womöglich die Verkaufspreisdifferenz in NeuStuttgart West und Süd erklärt werden. Hier sollte jedoch ein Zirkelschluss (Höherer Verkaufspreis -> Wohlhabendere Bewohner -> Höherer Verkaufspreis -> ...) vermieden werden. Das Ergebnis kann trotzdem für die Bestimmung des Preises eines neuen Hauses verwendet werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "**Aufgabenstellung**: _Bereinigen Sie die Daten und führen Sie ein sinnvolles Feature Engineering durch. Hinweis: Das kann auch für Punkt 2 bereits relevant sein (führen Sie das dann hier dann nochmals zusammenfassend auf)._"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Ausgeben aller Spalten, die entkodiert werden müssen.\n",
    "object_columns = train_data.dtypes[train_data.dtypes == 'object'].index\n",
    "\n",
    "for column in object_columns:\n",
    "    print(column, \":\", train_data.loc[:, column].unique(), \"\\n\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**! Attribute vom Typ \"object\" sind in Stringrepresentation und müssen codiert/quantifiziert/formatiert werden !**"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering\n",
    "\n",
    "* **Ausbaustufe**: Hier die Anzahl in Etagen in Fließkommazahlen übersetzen.\n",
    "* **Bebauungsdichte**: Label Encoding\n",
    "* **Besonderheiten**: Sehr dünn besetzt --> One Hot Encoding ? 0/1 ?\n",
    "* **Dachtyp**: Label Encoding\n",
    "* **Fassadenqual**: Label Encoding, \n",
    "    * Einteilung: Annahme: *sehr gut* gleich weit von *sehr schlecht*, Durchschnitt bei 0\n",
    "        * ['Sehr Schlecht', 'Schlecht', 'Durchschnitt', 'Gut', 'Sehr gut'] = [-2, -1, 0, 1, 2]\n",
    "    * Reihenfolge soll beibehalten werden! --> Ordinalskala\n",
    "    * Für *Schlecht* ist kein Datensatz vorhanden\n",
    "* **Fassadenzustand**: Wie bei **Fassadenqual**\n",
    "* **Kellerhoehe**: Wie bei **Fassadenqual**, aber Behandlung von Nullwerten\n",
    "* **Lage**: Label Encoding\n",
    "* **Typ**: Label Encoding"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ausbaustufe: Intervallskala\n",
    "Labelencoding mit passendem Flieskommawert aus Strings. Dadurch wird die Reihenfolge und Abstände der Werte beibehalten. *Sonstige* können keinem Wert zugeordnet werden, daher Null."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Ausbaustufe\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Erstellen und anwenden des Mappings\n",
    "Ausbaustufe_mapping = {\"Sonstige\": 0, \"1 Ebene\": 1.0, \"1,5 Ebenen\": 1.5, \"2 Ebenen\": 2.0, \"2,5 Ebenen\": 2.5}\n",
    "train_data[\"Ausbaustufe\"] = train_data[\"Ausbaustufe\"].replace(Ausbaustufe_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bebauungsdichte: Ordinalskala\n",
    "Verwendung von Labelencoding und Extraktion eines neuen Features Seelage. Alle möglichen Werte des Features Bebauungsdichte sind im Folgenden zu sehen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Bebauungsdichte\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Besonders interessant ist hier die Seelage, diese gehört nicht in die Kategorie \"Bebauungsdichte\", jedoch ist es sehr wahrscheinlich, dass ein Haus mit Seelage mehr kostet, als ein Haus ohne Seelage.\n",
    "Die Seelage wird extrahiert, und es wird ein neues Feature für sie angelegt. Bei den Werten der Bebauungsdichte \"Niedrig\", \"Mittel\" und \"Hoch\" handelt es sich um eine Ordinalskala, entsprechend ihrer Reihenfolge werden sie mit 1, 2 und 3 kodiert."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# neues Feature für Seelage: 1 wenn Seelage, 0 sonst\n",
    "Seelage = pd.Series(np.where(train_data[\"Bebauungsdichte\"] == \"Seelage\", 1.0, 0.0))\n",
    "train_data[\"Seelage\"] = Seelage"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ersetze Seelage als \"Unbekannt\"\n",
    "Bebauungsdichte_mapping = {\"Seelage\": 0.0, \"Unbekannt\": 0.0, \"Niedrig\": 1.0, \"Mittel\": 2.0, \"Hoch\": 3.0}\n",
    "train_data[\"Bebauungsdichte\"] = train_data[\"Bebauungsdichte\"].replace(Bebauungsdichte_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Besonderheiten: Nominalskala mit vielen Nullwerten"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Besonderheiten\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anzahl der Nullwerte\n",
    "train_data[\"Besonderheiten\"].isna().sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Anzahl - Kein Wasseranschluss: {train_data.Besonderheiten.value_counts()[\"kein Wasseranschluss\"]}')\n",
    "print(f'Anzahl - Neuverkauf: {train_data.Besonderheiten.value_counts()[\"Neuverkauf\"]}')"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Das Feature \"Besonderheiten\" enthält so gut wie nur Nullwerte (2086 Stück). Da es nur die zwei Werte \"kein Wasseranschluss\" und \"Neuverkauf\" gibt, würde es sich anbieten, mittels Hot One Encoding zwei neue Features anzulegen, und \"Besonderheiten\" zu löschen. Da es nur zwei Vorkommnisse von \"kein Wasseranschluss\" gibt, wird kein neues Feature angelegt, sondern im \"Data Cleaning\" die entsprechenden Datensätze gelöscht. Für die 190 Neuverkäufe lohnt es sich sehr wohl, ein neues Feature anzulegen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# neues Feature für Neuverkauf: 1 wenn Neuverkauf, 0 sonst\n",
    "Neuverkauf = pd.Series(np.where(train_data[\"Besonderheiten\"] == \"Neuverkauf\", 1.0, 0.0))\n",
    "train_data[\"Neuverkauf\"] = Neuverkauf\n",
    "\n",
    "# Besonderheiten Spalte löschen\n",
    "train_data = train_data.drop(columns=[\"Besonderheiten\"])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Mapping der Werte (True/False) auf Klartextbezeichungen\n",
    "train_data_neuverkauf = train_data.copy()\n",
    "train_data_neuverkauf[\"Neuverkauf\"] = train_data[\"Neuverkauf\"].replace(\n",
    "    {1.0: \"Neuverkauf\", 0: \"kein Neuverkauf\"}\n",
    ")\n",
    "\n",
    "show_boxplot(\"Neuverkauf\", \"des Neuverkaufs\", \"Neuverkauf ja/Nein\", data=train_data_neuverkauf)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aus dem obigen Boxplot wird ersichtlich, dass Neuverkäufe im Median höhere Verkaufspreise erziehlen, als Häuser die schon einmal verkauft wurden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dachtyp\n",
    "Hier wird ein klassisches Labelencoding angewandt. Die Verteilung der Werte zu den fünf Dachtypen wird dem `LabelEncoder` von `sklearn` überlassen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Dachtyp\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Durchführen des Encodings mit sklearn\n",
    "dachtyp_encoder = preprocessing.LabelEncoder()\n",
    "_ = dachtyp_encoder.fit(train_data[\"Dachtyp\"])\n",
    "train_data[\"Dachtyp\"] = dachtyp_encoder.transform(train_data[\"Dachtyp\"])\n",
    "\n",
    "\n",
    "# Anzeigen des durchgeführten Encodings\n",
    "dachtyp_encoder.classes_"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fassadenqualität\n",
    "Hier wird die Annahme getroffen, dass die Abstände zwischen den Werten \"Sehr Schlecht\", \"Schlecht\", \"Durchschnitt\", \"Gut\" und \"Sehr gut\" jeweils gleich sind. Dadurch bietet sich ein Mapping von -2 bis 2 an, wobei 0 den Durchschnitt repräsentiert.\n",
    "\n",
    "Es existiert zwar kein Eintrag mit der Fassadenqualität \"Schlecht\", aber das stört das Mapping nicht."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Fassadenqual\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Erstellen und Durchführen des Mappings\n",
    "sehr_schlecht_sehr_gut_mapping = {\n",
    "    \"Sehr Schlecht\": -2.0, \"Schlecht\": -1.0,\n",
    "    \"Durchschnitt\": 0.0,\n",
    "    \"Gut\": 1.0, \"Sehr gut\": 2.0\n",
    "}\n",
    "train_data[\"Fassadenqual\"] = train_data[\"Fassadenqual\"].replace(sehr_schlecht_sehr_gut_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fasadenzustand\n",
    "Da hier die Einträge die gleichen Werte auf der Skala von \"Sehr schlecht\" bis \"Sehr gut\" annehmen können, wird das gleiche Mapping verwendet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Fassadenzustand\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Mapping anwenden\n",
    "train_data[\"Fassadenzustand\"] = train_data[\"Fassadenzustand\"].replace(sehr_schlecht_sehr_gut_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kellerhoehe\n",
    "Auch die Werte der Kellerhöhe befinden sich im Bereich von \"Sehr schlecht\" bis \"Sehr gut\", weswegen hier das gleiche Mapping angewendet wird.\n",
    "\n",
    "Hier ist zu beachten, dass Nullwerte existieren. Diese werden entfernt, da die Kellerhöhe eine hohe Korrelation mit dem Verkaufspreis aufweist und das Füllen mit Annahmen die Vorhersage verfälschen könnte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Entfernen von Nullwerten\n",
    "train_data.dropna(inplace=True, subset=[\"Kellerhoehe\"])\n",
    "train_data[\"Kellerhoehe\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Mapping anwenden\n",
    "train_data[\"Kellerhoehe\"] = train_data[\"Kellerhoehe\"].replace(sehr_schlecht_sehr_gut_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lage\n",
    "Bei der Lage wird das Encoding der Labels wieder dem `LabelEncoder` überlassen.\n",
    "\n",
    "Der einzelne Nullwert wird entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data.dropna(inplace=True, subset=[\"Lage\"])\n",
    "train_data[\"Lage\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Durchführen des Encodings mit sklearn\n",
    "Lage_encoder = preprocessing.LabelEncoder()\n",
    "_ = Lage_encoder.fit(train_data[\"Lage\"])\n",
    "train_data[\"Lage\"] = Lage_encoder.transform(train_data[\"Lage\"])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Typ\n",
    "Bei dem Typ ist ebenfalls kein direktes Zahlenmapping möglich, weswegen hier der `LabelEncoder` zur Hilfe gezogen wird.\n",
    "\n",
    "Nullwerte werden hier durch \"Unbekannt\" ersetzt, da es 81 Nullwerte gibt. Das Entfernen von so vielen Werten könnte eine Verzerrung der Vorhersage zur Folge haben."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Typ\"].unique()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Typ\"].isna().sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# auffüllen von Nullwerten mit \"unbekannt\"\n",
    "train_data[\"Typ\"] = train_data[\"Typ\"].fillna(value=\"Unbekannt\")\n",
    "\n",
    "# Durchführen des Encodings mit sklearn\n",
    "Typ_encoder = preprocessing.LabelEncoder()\n",
    "_ = Typ_encoder.fit(train_data[\"Typ\"])\n",
    "train_data[\"Typ\"] = Typ_encoder.transform(train_data[\"Typ\"])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Datenbereinigung\n",
    "\n",
    "Hier werden Ausreißer entfernt, die in der Data Exploration entdeckt wurden. Bevor ein Ausreißer entfernt wird, wird analysiert, ob es sich hierbei um einen unbrauchbaren Ausreißer, oder ein sinnvolles Maximum handelt. Dies wird mit Hilfe von Fachwissen entschieden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Anzahl Zimmer\n",
    "\n",
    "Hier werden alle Datensatze mit 0 Zimmern entfernt. Dies hat den Grund, dass ein Haus ohne Zimmer als Kellerwohnung definiert ist. Es gibt jedoch nur sechs Verkäufe von Kellerwohnungen im Datensatz. Diese sind nicht repräsentativ für den ganzen Datensatz und werden als Ausreiser gewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# AnzahlZimmer: Entfernen von Datensätzen mit null Zimmern --> Kellerwohnungen\n",
    "train_data = train_data[train_data[\"AnzahlZimmer\"] != 0]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Ausbaustufe\n",
    "\n",
    "Hier wird zuerst analysiert, welchen Einfluss die Ausbaustufe auf den Preis hat. Ist der Einfluss gering, wird die Ausbaustufe später ignoriert. \n",
    "\n",
    "Da der Einfluss der Ausbaustufe sehr gering ist (vgl. Korrelationsheatmap: 0.14), wird dieses Feature sehr wahrscheinlich nicht verwendet, weswegen diese Datensätz drin gelassen werden können. Im Boxplots ist ebenfalls kein wesentlicher Zusammenhang zu erkennen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "show_boxplot(\"Ausbaustufe\", \"der Ausbaustufe\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baeder\n",
    "\n",
    "Aufgrund des großen Einflusses der Bäder auf den Verkaufspreis werden hier keine Daten entfernt. Die Spalte enthält zusätzlich keine unzulässigen Werte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### BaederUG\n",
    "\n",
    "Hier müssen keine Daten bereinigt werden. Die Spalte enthält keine Null- oder unzulässige Werte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baujahr\n",
    "\n",
    "Die Baujahr-Spalte enthält keine ungültigen Werte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bebauungsdichte\n",
    "\n",
    "Die Spalte enthält \"Unbekannt\" Werte. Dazu gehören auch die Werte, welche \"Seelange\" enthalten haben und auf \"Unbekannt\" gesetzt wurden. Diese werden zunächst belassen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dachtyp\n",
    "Dachtyp enthält keine ungültigen Werte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### EG_qm\n",
    "Die Spalte EG_qm enthält keine ungültigen Werte. Es wird auf Ausreißer geprüft:"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Beschriftungen\n",
    "axes.set_title(\"Scatterplot über die unbereinigten EG_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Erdgeschossfläche in m²\")\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "sns.scatterplot(data=train_data, x=\"EG_qm\", y=\"Z_Verkaufspreis\", ax=axes)\n",
    "\n",
    "# Rote Linie zeichnen\n",
    "_ = plt.plot([260, 260], [800000, 0], linewidth=3, color=\"red\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Die fünf größten Erdgeschossflächen (rechts von der roten Linie) weichen stark vom allgemeinen Trend ab. Dies kann aus dem obigen Scatterplot abgelesen werden. Daher werden diese entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtern der Daten\n",
    "train_data = train_data[train_data[\"EG_qm\"] <= 260]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Der folgende Scatterplot zeigt die bereinigten Daten."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Beschriftungen\n",
    "axes.set_title(\"Scatterplot über die bereinigten EG_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Erdgeschossfläche in m²\")\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "_ = sns.scatterplot(data=train_data, x=\"EG_qm\", y=\"Z_Verkaufspreis\", ax=axes)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fassadenqualität\n",
    "\n",
    "Hier muss nichts bereinigt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fassadenzustand\n",
    "Hier muss nichts bereinigt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Garagen\n",
    "Hier muss nichts bereinigt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gesamteindruck\n",
    "Muss zwischen 1 und 5 sein, jedoch gibt es drei Datensätze mit dem Wert null, diese werden entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "(train_data[\"Gesamteindruck\"] == 0).sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtern der Daten\n",
    "train_data = train_data[train_data[\"Gesamteindruck\"] > 0]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Grundstueck_qm\n",
    "\n",
    "Hier sind zwar keine ungültigen Werte enthalten, allerdings beinhaltet die Spalte viele Ausreißer. Diese werden in dem folgenden Scatterplot rechts der roten Linie dargestellt und entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Beschriftungen\n",
    "axes.set_title(\"Scatterplot über die unbereinigten Grundstueck_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Grundstückfläche in m²\")\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "sns.scatterplot(data=train_data, x=\"Grundstueck_qm\", y=\"Z_Verkaufspreis\", ax=axes)\n",
    "\n",
    "# Rote Linien zeichnen\n",
    "plt.plot([3000, 16500], [400000, 400000], linewidth=3, color=\"red\")\n",
    "_ = plt.plot([3000, 3000], [400000, 0], linewidth=3, color=\"red\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alle Grundstücke mit einer Fläche größer 3 000 m² und einem Verkaufspreis unter 400 000 € sind hier klare Ausreißer. Sie werden entfernt. Das sind die Datenpunkte rechts/unter der roten Linie."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtern der Daten\n",
    "train_data = train_data[train_data[\"Grundstueck_qm\"] < 3000].append(train_data[train_data[\"Z_Verkaufspreis\"] > 400000])"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Beschriftungen\n",
    "axes.set_title(\"Scatterplot über die bereinigten Grundstueck_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Grundstückfläche in m²\")\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "_ = sns.scatterplot(data=train_data, x=\"Grundstueck_qm\", y=\"Z_Verkaufspreis\", ax=axes)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kamine\n",
    "\n",
    "Es existiert ein einzelner Eintrag mit vier Kaminen. Dieser wird entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "(train_data[\"Kamine\"] == 4).sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtern der Daten\n",
    "train_data = train_data[train_data[\"Kamine\"] < 4]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KellerQual\n",
    "\n",
    "Hier muss keine Bereinigung durchgeführt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Keller_qm\n",
    "\n",
    "Nach Betrachtung des Scatterplots sind hier keine Ausreißer vorhanden, die entfernt werden müssten."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Beschriftungen\n",
    "axes.set_title(\"Scatterplot über die Keller_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Kellerfläche in m²\")\n",
    "\n",
    "# Anzeigen des Scatterplots\n",
    "_ = sns.scatterplot(data=train_data, x=\"Keller_qm\", y=\"Z_Verkaufspreis\", ax=axes)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Kellerhöhe\n",
    "\n",
    "Hier existiert ein einzelner \"Sehr schlecht\" Wert. Dieser wird entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Filtern des Datensatzes\n",
    "train_data = train_data[train_data[\"Kellerhoehe\"] > -2]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Lage\n",
    "\n",
    "Hier muss keine Bereinigung durchgeführt werden. Es gibt z.B. keine Nullwerte."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ToilettenEG\n",
    "\n",
    "Hier müssen keine Daten bereinigt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ToilettenUG\n",
    "Hier müssen keine Daten entfernt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Typ\n",
    "Beim Labelencoding wurden Nullwerte durch \"Unbekannt\" ersetzt, welchen dann das Label 0 zugewiesen wurde.\n",
    "--> Vorerst keine Anpassung"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Umgebaut\n",
    "\n",
    "Hier existieren Fließkommazahlen zwischen 1961 und 2021. Der Datensatz enthält keine Nullwerte. --> Keine Anpassung nötig"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Umgebaut\"].isna().sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Es sollten jedoch Datensätze entfernt werden, bei denen Häuser früher umgebaut wurden, als ihr Baujahr. Davon gibt es genau einen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anzeigen der Datensätze, wo vor dem Baujahr umgebaut wurden\n",
    "train_data[train_data[\"Umgebaut\"] < train_data[\"Baujahr\"]].loc[:, [\"Umgebaut\", \"Baujahr\"]]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Löschen des einzelnen Eintrags\n",
    "train_data.drop(train_data[train_data[\"Umgebaut\"] < train_data[\"Baujahr\"]].index, inplace=True)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verkaufsjahr\n",
    "Verhält sich wie \"Umgebaut\", keine Anpassung "
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verkaufsmonat\n",
    "Keine Anpassung"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Wohnflaeche_qm\n",
    "\n",
    "Der nachfolgende Scatterplot zeigt, dass hier keine Ausreißer vorhanden sind, die entfernt werden sollten. Alle Werte befinden sich in einem aktzeptablen Bereich."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Anzeigen des Scatterplots\n",
    "\n",
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "# Setzen der Achsenbeschriftungen und des Titels\n",
    "axes.set_title(\"Scatterplot über die Wohnflaeche_qm\")\n",
    "axes.set_ylabel(\"Verkaufspreis in Euro\")\n",
    "axes.set_xlabel(\"Wohnfläche in m²\")\n",
    "\n",
    "# Zeichen des Scatterplots\n",
    "_ = sns.scatterplot(data=train_data, x=\"Wohnflaeche_qm\", y=\"Z_Verkaufspreis\", ax=axes)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "train_data[\"Wohnflaeche_qm\"].isna().sum()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Seelage\n",
    "\n",
    "\n",
    "Hier handelt es sich um eine Attribut, das im Feature Engineering erstellt wurde. Es ist keine Bereinigung nötig."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Neuverkauf\n",
    "\n",
    "Hierbei handelt es sich um ein Attribut, welches im Feature Engineering erstellt wurde. Es ist daher keine Anpassung nötig."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Korrelationsmatrix nach der Aufbereitung und Bereinigung des Datensatzes"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Zeichnen einer Korrelationsmatrix Heatmap mit dreieckigem Ausschnitt\n",
    "\n",
    "plt.figure(figsize=(22, 15))\n",
    "# Definition einer Maske, um die Dopplung der Korrelationen zu vermeiden\n",
    "mask = np.triu(np.ones_like(train_data.corr(), dtype=bool))\n",
    "heatmap = sns.heatmap(train_data.corr(), mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "_ = heatmap.set_title('Korrelations Heatmap mit allen Features', fontdict={'fontsize': 18}, pad=16)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nach der Dataprepartion haben sich die Korrelationen vieler Features mit dem Verkaufspreis gesteigert. Durch das Encoding sind neue Features mit einer hohen Korrelation zum Verkaufspreis dazugekommen, z.B. :\n",
    "\n",
    "* Fassadenqual\n",
    "* Kellerhoehe"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Modeling - Regression mit Interferenz\n",
    "\n",
    "**Aufgabenstellung**: _Führen Sie mit geeigneten Verfahren der Regression (Linear / Lasso / Ridge) eine Vorhersage des Preises (Z_Verkaufspreis) durch, der akzeptabel in der Evaluation abschneidet und Verständnis ermöglicht. Erklären Sie die identifizierten Zusammenhänge menschenverständlich als Text (mit nachvollziehbarer Anzahl der Merkmale)._\n",
    "\n",
    "### Protokoll über die vorgenommenen Änderungen\n",
    "Insgesamt wurde eine **Backward** Auswahl getroffen. Es wurden also nach und nach Features gestrichen.\n",
    "\n",
    "\n",
    "1. Zuerst wurde die Regression mit allen Features durchgeführt. Hier wurde ein Score von ~0,88 erreicht. Allerdings war es hier unmöglich, die Koeffizienten der Regression mit knapp 30 Features zu interpretieren. Daher der nächste Schritt:\n",
    "2. Danach wurden die Features auf diejenigen eingegrenzt, dessen Korrelation größer als 0,5, bzw. kleiner als -0,5 ist. Dadurch verringerte sich der R²-Wert auf 0,849. Hierbei handelt es sich um ein sehr gutes Ergebnis, wenn man bedenkt, dass die Vorhersage mit nur zehn Features gemacht wurde.\n",
    "3. Da der Koeffizient der Baeder überraschend niedrig (ca. -24 0000) war, wurde die Datenbereinigung bei den Bädern (Entfernen von Einträgen mit keinen Baedern) rückgängig gemacht. Durch diese Maßnahme konnte der Score auf knapp 0,85 erhöht werden. Der Koeffizient der Baeder ist mit ca. -22 000 immernoch überraschend niedrig. Die Korrelationsmatrix suggeriert hier, dass der Koeffizient auf jeden Fall positiv sein sollte.\n",
    "4. Um die Koeffizienten der einzelnen Features besser vergleichen und auswerten zu können, wurden alle Features auf eine Einheitsskala gebracht. Dies wurde umgesetzt, indem jedes Features durch das jeweilige Maximum geteilt wurde.\n",
    "5. Die Einheitsskala bringt leider keinen Mehrwert und wurde daher wieder entfernt.\n",
    "6. Der nächste Schritt war das Entfernen von Features abhängig von den Korrelationen zu anderen Attributen. Hier wurde als erstes *EG_qm* entfernt, da dieses Attribut eine Korrelation von 0.9 zu *Keller_qm* hat. Der R²-Wert hat sich durch diese Maßnahme kaum verändert.\n",
    "7. Daraufhin wurde das Feature *Baeder* entfernt, da dieses mit einer Korrelation von 0.65 stark an die Wohnfläche gebunden ist. Der Score liegt nun bei ~0,842.\n",
    "8. Eine weitere starke Korrelation ist zwischen Kellerhöhe und Baujahr vorhanden. Nach dem Entfernen der Kellerhöhe liegt der Score der Regression bei 0,836. Daher wurde die Kellerhöhe beibehalten.\n",
    "\n",
    "Insgesamt sind die Unterschiede von der normalen zu der Lasso / Ridge Regression sehr gering. Die Lasso Regression eliminiert keine weiteren Features, wenn bereits händisch gefiltert wird.\n",
    "\n",
    "### Cross-Validierung\n",
    "Schlussendlich wurde eine Method zum Durchführen der Cross-Validation geschrieben, sodass die Fehlermetriken einheitlich ausgegeben werden. Die Methode `create_regression()` ist dadurch überflüssig und nur zur Vollständigkeit noch vorhanden. Hier konnte beobachtet werden, dass die R²-Werte der Cross-Validation (teilweise deutlich) unter den Werten der manuellen Durchführung der Regression liegen (Was vermutlich an einem besonders günstigen ursprünglichen Train/Testplit liegt).\n",
    "\n",
    "Selbst nach dem erneuten Hinzunehmen der drei entfernten Attribute (*Baeder, EG_qm* und *Kellerhöhe*) verbessert sich der R²-Wert der Cross-Validierung um nur 0,01. Daher wurden die Attribute weiterhin von der Regression ausgeschlossen, da sie offensichtlich kaum Veränderung bewirken.\n",
    "\n",
    "Insgesamt wurde der Score von ~0,77 für sieben Attribute akzeptiert.\n",
    "\n",
    "Der Train-Test-Split wird weiterhin benötigt, da sonst die Koeffizienten der Regression nicht abgerufen werden können. Deshalb wird in `log_coefficients()` die `fit()`-Methode der Regression aufgerufen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "# Create and fit a regression to given train data\n",
    "def create_regression(x_train_data, y_train_data, method=\"normal\", hyperparams=None):\n",
    "    \"\"\"\n",
    "    Wende normale, Lasso oder Ridge Regression auf einen gegeben Datensatz an, und gib das trainierte Regressionsmodell aus.\n",
    "    \"\"\"\n",
    "\n",
    "    if hyperparams is None:\n",
    "        hyperparams = {}\n",
    "\n",
    "    if method == \"lasso\":\n",
    "        reg = Lasso(**hyperparams)\n",
    "    elif method == \"ridge\":\n",
    "        reg = Ridge(**hyperparams)\n",
    "    else:\n",
    "        reg = LinearRegression()\n",
    "\n",
    "    reg.fit(x_train_data, y_train_data)\n",
    "\n",
    "    return reg"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auswahl der Attribute für die Regression"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Auswahl der verwendeten Spalten für die Regression. \n",
    "regression_columns = [\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\", \"Z_Verkaufspreis\"]\n",
    "\n",
    "regression_feature_selection = train_data.loc[:, regression_columns]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# split the data into test and training data\n",
    "X_reduced = regression_feature_selection.drop(columns=[\"Z_Verkaufspreis\"])\n",
    "Y_reduced = regression_feature_selection[\"Z_Verkaufspreis\"]\n",
    "\n",
    "# entfernen von \"Z_Verkaufspreis\" aus den Testdaten\n",
    "X_full = train_data.drop(columns=[\"Z_Verkaufspreis\"])\n",
    "Y_full = train_data[\"Z_Verkaufspreis\"]\n",
    "\n",
    "# metrics to evaluate\n",
    "metrics = ['r2', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_root_mean_squared_error']"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# ursprünglicher Train/Testsplit\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X_reduced, Y_reduced, test_size=0.2, random_state=100)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### R²-Wert mit zugehörigen Features\n",
    "**Dieser Abschnitt stellt den Vorgang der Eliminierung von Attributen dar und wurde vor der Cross-Validation durchgeführt.**\n",
    "\n",
    "[\"Baujahr\",\"Fassadenqual\",\"Garagen\",\"Kamine\",\"Keller_qm\",\"Umgebaut\",\"Kellerhoehe\",\"Wohnflaeche_qm\",\"Z_Verkaufspreis\",\"Baeder\",\"EG_qm\"]\n",
    "\n",
    "0.8497\n",
    "\n",
    "[\"Baujahr\",\"Fassadenqual\",\"Garagen\",\"Kamine\",\"Keller_qm\",\"Umgebaut\",\"Kellerhoehe\",\"Wohnflaeche_qm\",\"Z_Verkaufspreis\",\"EG_qm\"]\n",
    "\n",
    "0.8420\n",
    "\n",
    "[\"Baujahr\",\"Fassadenqual\",\"Garagen\",\"Kamine\",\"Keller_qm\",\"Umgebaut\",\"Kellerhoehe\",\"Wohnflaeche_qm\",\"Z_Verkaufspreis\"]\n",
    "\n",
    "0.8421\n",
    "\n",
    "[\"Baujahr\",\"Fassadenqual\",\"Garagen\",\"Kamine\",\"Keller_qm\",\"Umgebaut\",\"Wohnflaeche_qm\",\"Z_Verkaufspreis\"]\n",
    "\n",
    "0.8366"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def perform_cross_validation(reg, x=X_reduced, y=Y_reduced):\n",
    "    \"\"\"\n",
    "\n",
    "    Durchführung einer 5-Fold Crossvalidation für ein gegebenes Regressionsmodell. Für jede Fold werden die in \"metrics\" definierten \n",
    "    Metriken angewendet, zusätzlich wird das arithmetische Mittel für jede Metrik über alle Folds gebildet.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    validation = cross_validate(reg, x, y, cv=5, scoring=metrics)\n",
    "\n",
    "    print(\"Cross-Validation:\")\n",
    "    for key, value in [item for item in validation.items() if \"time\" not in item[0]]:\n",
    "        print(f\"\\n  - {key.replace('test_', '')}:\")\n",
    "        for val in value:\n",
    "            print(f\"\\t{val}\")\n",
    "\n",
    "        print(f'\\n\\tmean: {np.around(np.mean(value), decimals=4)}, var: {np.around(np.var(value), decimals=4)}')"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def log_coefficients(reg, x=X_reduced, y=Y_reduced):\n",
    "    \"\"\"\n",
    "    Trainiert einen Regressor auf gegebenen Daten und gibt die Werte der Regressionsparameter für das fertige Modell aus.\n",
    "    \"\"\"\n",
    "\n",
    "    # Zufälliger Train/Testsplit\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=100)\n",
    "\n",
    "    # Fitten des Modells\n",
    "    reg.fit(x_train, y_train)\n",
    "\n",
    "    try:\n",
    "        print(\"\\nKoeffizienten:\")\n",
    "        for index, col in enumerate(reg.feature_names_in_):\n",
    "            print(f\"  - {col}: {reg.coef_[index]}\")\n",
    "\n",
    "        print(\"---------------------\")\n",
    "        print(\"  - Intercept\", reg.intercept_)\n",
    "    except AttributeError as e:\n",
    "        print(\"Error: fit() not called\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression\n",
    "Im folgenden wird eine lineare Regression mit allen Attributen des Datensatzes durchgeführt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "regression_normal = LinearRegression()\n",
    "\n",
    "perform_cross_validation(regression_normal, x=X_full, y=Y_full)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "log_coefficients(regression_normal)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression mit reduzierten Attributen\n",
    "Im folgenden wird eine lineare Regression mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "regression_normal_reduced = LinearRegression()\n",
    "\n",
    "perform_cross_validation(regression_normal_reduced)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "log_coefficients(regression_normal)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Lasso Regression\n",
    "Im folgenden wird eine Lasso Regression mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "regression_lasso = Lasso()\n",
    "\n",
    "perform_cross_validation(regression_lasso)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "log_coefficients(regression_lasso)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression\n",
    "Im folgenden wird eine Ridge Regression mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "regression_ridge = Ridge()\n",
    "\n",
    "perform_cross_validation(regression_ridge)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "log_coefficients(regression_ridge)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Modeling - Best of Class\n",
    "\n",
    "**Aufgabenstellung**: _Vergleichen und optimieren Sie ggfs. ein oder mehrere andere Verfahren zur Vorhersage des Verkaufspreises (Z_Verkaufspreis). Gehen Sie vor wie in der Vorlesung gelehrt mit Trainings- und Validierungsdaten. Vergleichen und optimieren Sie. Interpretieren Sie das Ergebnis und den Einfluss der Dimensionen (falls möglich)._\n",
    "\n",
    "### Hinweis\n",
    "Hier wurde sich der Methode und Parameterauswahl aus Aufgabe 4 bedient."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest\n",
    "Im folgenden wird eine Random Forest Regression mit einer reduzierten Anzahl an Attributen durchgeführt. (\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5 Fold Crossvalidation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "randomForest = RandomForestRegressor(n_estimators=50)\n",
    "\n",
    "perform_cross_validation(randomForest)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosted Tree\n",
    "Im folgenden wird eine Gradient Boosted Trees Regression mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gradient_boosted_tree = GradientBoostingRegressor(random_state=0)\n",
    "\n",
    "perform_cross_validation(gradient_boosted_tree)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Passive Agressive Regressor\n",
    "Im folgenden wird eine Regression durch den Passive Agressive Regressor mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "\n",
    "pa_regressor = PassiveAggressiveRegressor()\n",
    "\n",
    "perform_cross_validation(pa_regressor)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Support Vector Regressor\n",
    "Im folgenden wird eine LSV Regression mit einer reduzierten Anzahl an Attributen durchgeführt. \n",
    "(\"Baujahr\", \"Fassadenqual\", \"Garagen\", \"Kamine\", \"Keller_qm\", \"Kellerhoehe\", \"Umgebaut\", \"Wohnflaeche_qm\"). Diese wird in einer 5-Fold-Cross-Validation mit verschiedenen Fehlermetriken bewertet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "supportVector_regressor = SVR(kernel=\"linear\")\n",
    "\n",
    "perform_cross_validation(supportVector_regressor)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Grid Search für Gradient Boosted Tree\n",
    "\n",
    "Nach Vergleich der Ergebnisse aus Aufgabe 4 und 5 hat sich **Gradient Boosted Tree** als beste Methode (Durchschnittlicher Score von 0,87) herausgestellt. Daher wird ein **finales Hyperparametertuning** für die Regression durchgeführt. Das Tuning wird über eine Methode namens *GridSearch* erreicht, welche in sklearn über `GridSearchCV` implementiert ist.\n",
    "\n",
    "Wurde als bester Parameter einer der äußersten (der Kleinste / Größste) ausgewählt, wurden die Werte an diesem Ende erweitert und am anderen Ende entfernt."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Durchführung einer Gridsearch über die Parameter learning_rate, n_estimators, max_depth, min_samples_split\n",
    "# Aus Performancegründen wurde diese auskommentiert\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(gradient_boosted_tree, {\n",
    "    \"learning_rate\": [0.06, 0.075, 0.8],\n",
    "    \"n_estimators\": [95, 100, 105, 110, 125],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"min_samples_split\": [2, 3, 4, 5]\n",
    "}, n_jobs=-1, verbose=1)\n",
    "\n",
    "# grid_search.fit(X_reduced, Y_reduced)\n",
    "\n",
    "# print(\"Die besten Parameter lauten:\")\n",
    "# print(\"\".join([f\"  - {key}: {value}\\n\" for key, value in grid_search.best_params_.items()]))\n",
    "# print(\"und ergeben einen Score von:\", grid_search.best_score_)\n",
    "\n",
    "# grid_search.cv_results_"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Erste Iteration\n",
    "```\n",
    "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
    "\n",
    "Die besten Parameter lauten:\n",
    "- learning_rate: 0.075\n",
    "- max_depth: 5\n",
    "- min_samples_split: 3\n",
    "- n_estimators: 100\n",
    "\n",
    "und ergeben einen Score von: 0.8787977483676288\n",
    "```\n",
    "\n",
    "#### Zweite Iteration\n",
    "```\n",
    "Fitting 5 folds for each of 256 candidates, totalling 1280 fits\n",
    "\n",
    "Die besten Parameter lauten:\n",
    "- learning_rate: 0.075\n",
    "- max_depth: 5\n",
    "- min_samples_split: 3\n",
    "- n_estimators: 100\n",
    "\n",
    "und ergeben einen Score von: 0.8787977483676288\n",
    "```\n",
    "\n",
    "#### Dritte Iteration\n",
    "```\n",
    "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
    "\n",
    "Die besten Parameter lauten:\n",
    "- learning_rate: 0.075\n",
    "- max_depth: 5\n",
    "- min_samples_split: 3\n",
    "- n_estimators: 105\n",
    "\n",
    "und ergeben einen Score von: 0.8789874753412954\n",
    "```\n",
    "\n",
    "#### Finale Hyperparameter\n",
    "Als finale Hyperparameter wurden die Parameter der 3. Iteration übernommen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Evaluation und Test\n",
    "\n",
    "**Aufgabenstellung**: _Schließen Sie die Aufgabe mit einer finalen Evaluation der Vorhersagequalität ab. Stellen Sie sicher, dass die Testdatei (data_for_testing_test.csv) ladbar ist und mit zurückgehaltenen Testdaten data_for_test.csv ersetzt werden kann, um einen Benchmark zu erstellen. Kommentieren Sie die Stelle mit dem Kommentar „#HIER DATEINAMEN ERSETZEN“. Geben Sie für die Testdaten aus: R2, MSE, RMSE, MAPE, MAX._"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Einlesen der Testdatei\n",
    "\n",
    "# HIER DATEINAMEN ERSETZEN\n",
    "test_data = pd.read_csv('data_for_testing_test.csv', delimiter=\";\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nun muss sichergestellt werden, dass die Trainings- und Testdaten die selbe Form besitzen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Extrahieren der relevanten Informationen\n",
    "test_data_reduced = test_data.loc[:, regression_columns]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Zusätzlich muss das Label-Encoding des Trainings-Datensatzes auf den relevanten Attribute der Testdaten durchgeführt werden."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Labelencoding der relevanten Features für den Testdatensatz\n",
    "\n",
    "sehr_schlecht_sehr_gut_mapping = {\n",
    "    \"Sehr Schlecht\": -2.0, \"Schlecht\": -1.0,\n",
    "    \"Durchschnitt\": 0.0,\n",
    "    \"Gut\": 1.0, \"Sehr gut\": 2.0\n",
    "}\n",
    "\n",
    "# Anwendung des Mappings\n",
    "test_data_reduced[\"Fassadenqual\"] = test_data_reduced[\"Fassadenqual\"].replace(sehr_schlecht_sehr_gut_mapping)\n",
    "\n",
    "test_data_reduced[\"Kellerhoehe\"] = test_data_reduced[\"Kellerhoehe\"].replace(sehr_schlecht_sehr_gut_mapping)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "X_test = test_data_reduced.drop(columns=[\"Z_Verkaufspreis\"])\n",
    "Y_test = test_data_reduced[\"Z_Verkaufspreis\"]"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trick 17: Finales Trainieren des Modells auf den gesamten Daten mit ausgewählten Hyperparametern\n",
    "\n",
    "Im Anschluss werden gewisse Fehlermetriken für die Testdaten berechnet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, max_error\n",
    "\n",
    "# Erstellen des Gradient Boosting Regressors mit den gewählten Hyperparametern.\n",
    "gradient_boosted_tree = GradientBoostingRegressor(\n",
    "    random_state=0,\n",
    "    learning_rate=0.075,\n",
    "    max_depth=5,\n",
    "    min_samples_split=3,\n",
    "    n_estimators=105\n",
    ")\n",
    "\n",
    "# Trainieren des Modells\n",
    "gradient_boosted_tree.fit(X_reduced, Y_reduced)\n",
    "\n",
    "# Vorhersage auf den Testdaten\n",
    "y_pred = gradient_boosted_tree.predict(X_test)\n",
    "\n",
    "# Ausgabe von Fehlermetriken\n",
    "print(f\"R2:\\t{np.around(gradient_boosted_tree.score(X_test, Y_test), decimals=4)}\")\n",
    "print(f\"MSE:\\t{np.around(mean_squared_error(Y_test, y_pred), decimals=4)}\")\n",
    "print(f\"RMSE:\\t{np.around(np.sqrt(mean_squared_error(Y_test, y_pred)), decimals=4)}\")\n",
    "print(f\"MAPE:\\t{np.around(mean_absolute_percentage_error(Y_test, y_pred), decimals=4)}\")\n",
    "print(f\"MAX:\\t{np.around(max_error(Y_test, y_pred), decimals=4)}\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Deployment\n",
    "\n",
    "**Aufgabenstellung**: _Erstellen Sie eine Anleitung oder Handreichung für den Immobilienverein aus Aufgabe 1 basierend auf allen Erkenntnissen. Sie können Markup und erklärende Visualisierungen innerhalb des .ipynb nutzen. Dies soll alle\n",
    "für den Verein wichtigen Erkenntnisse zusammenfassen (auch wenn dadurch Redundanz in der Abgabe entsteht) und maximal 2 Seiten im pdf-Ausdruck umfassen, welche komplett eigenständig lesbar sein sollen._"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Anleitung für den Immobilienverein\n",
    "\n",
    "### Verkaufspreisvorhersage\n",
    "Die Erkenntnisse der Datenanalyse mit dem Ziel den **Verkaufspreis** einer Immobilie aufgrund von gegebenen Attributen **vorherzusagen**, werden in den nächsten Abschnitten vorgestellt.\n",
    "\n",
    "Die nachfolgende Tabelle zeigt die **Attribute**, die den **Verkaufspreis** am stärksten **beeinflussen**. Die *Eigenschaft* stellt den Name des Attributs dar, die *Bezeichung* den Namen im Datensatz.\n",
    "\n",
    "| **Eigenschaft**    | **Bezeichnung** |\n",
    "|--------------------|-----------------|\n",
    "| Wohnfläche (m²)    | *Wohnflaeche_qm*|\n",
    "| EG-Fläche (m²)     | *EG_qm*         |\n",
    "| Keller (m²)        | *Keller_qm*     |\n",
    "| Kellerhöhe         | *Kellerhoehe*   |\n",
    "| Anzahl Bäder       | *Baeder*        |\n",
    "| Anzahl Garagen     | *Garagen*       |\n",
    "| Fassadenqualität   | *Fassadenqual*  |\n",
    "| Baujahr            | *Baujahr*       |\n",
    "| Letzte Renovierung | *Umgebaut*      |\n",
    "\n",
    "Aufgrund von diversen Abhängigkeiten der Attribute untereinander, wurden die folgenden Eigenschaften für die **finale Preisvorhersage** ausgesucht:\n",
    "\n",
    "| **Eigenschaft**    | **Bezeichnung** |\n",
    "|--------------------|-----------------|\n",
    "| Wohnfläche (m²)    | *Wohnflaeche_qm*|\n",
    "| Keller (m²)        | *Keller_qm*     |\n",
    "| Kellerhöhe         | *Kellerhoehe*   |\n",
    "| Anzahl Kamine      | *Kamine*        |\n",
    "| Anzahl Garagen     | *Garage*        |\n",
    "| Fassadenqualität   | *Fassadenqual*  |\n",
    "| Baujahr            | *Baujahr*       |\n",
    "| Letzte Renovierung | *Umgebaut*      |\n",
    "\n",
    "Das Angeben dieser Attribute in den *Gradient Boosted Tree* liefert einen **Preisvorschlag**, der **bis zu 95 % genau** ist und im Mittel um weniger als 15 000 € vom eigentlichen Verkaufspreis abweicht. Dieser Preisvorschlag dient als sehr gute **Verhandlungsgrundlage** für die Preisverhandlung mit dem Käufer, beziehungsweise Verkäufer. Auch kann somit eine erste Abschätzung getroffen werden, ob der Verkaufspreis einer neue Immobilie gerechtfertigt ist.\n",
    "\n",
    "Die Preisvorhersage kann ebenfalls genutzt werden, um **Immobilienexposes in Kategorien zu gliedern**. Vorgeschlagene Kategorien lauten:\n",
    "- **Direkt kaufen**: Die Immobilie kann ohne Bedenken gekauft werden, wenn der Listenpreis **weniger als 10 %** über der Vorhersage liegt. Dies gilt auch für Listenpreise, die unter dem Preisvorschlag der Software liegen.\n",
    "- **Abwarten**: Ist der Listenpreis **zwischen 10 und 15 %** größer als die Vorhersage, sollte der Dialog mit dem Verkäufer gesucht und dessen Begründung für den hohen Preis eingeholt werden.\n",
    "- **Schlechtes Angebot**: Weicht der Listenpreis um **mehr als 20 %** von der Preisvorhersage ab, handelt es sich in den meisten Fällen um ein schlechtes Angebot. Hier ist eine Verhandlung unabdingbar.\n",
    "\n",
    "Da der *Gradient Boosted Tree* nicht immer zur Hand liegen wird, wurde eine **Formel** zur **einfachen Berechnung** des Verkaufspreises erstellt. Sie berechnet den Verkaufspreis anhand von acht Attributen mit einer **Genauigkeit** von ca. **77 %** und einem durchschnittlichen Fehler von ca. +- 32 000 € Abweichung vom tatsächlichen Verkaufspreis.\n",
    "\n",
    "$Verkaufspreis = - 48*Baujahr + 35527*Fassadenqualität + 11824*Garagen + 16106*Kamine + 641*Keller\\_qm\n",
    "                 + 19484*Kellerhöhe + 272*Umgebaut + 658*Wohnfläche\\_qm - 463361$\n",
    "\n",
    "Dabei wird für die $Fassadenqualität$ und $Kellerhöhe$ die folgende Zuordnung verwendet:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th>$Fassadenqualität$</th>\n",
    "    <th>$Kellerhöhe$</th>\n",
    "</tr>\n",
    "<tr><td>\n",
    "\n",
    "| **Qualitätsstufe** | **Wert** |\n",
    "|--------------------|---------:|\n",
    "|Sehr schlecht       |   -2     |\n",
    "|Schlecht            |   -1     |\n",
    "|Durchschnitt        |    0     |\n",
    "|Gut                 |    1     |\n",
    "|Sehr gut            |    2     |\n",
    "\n",
    "</td><td>\n",
    "\n",
    "| **Kellerhöhe (cm)**| **Wert** |\n",
    "|--------------------|---------:|\n",
    "| < 175              |   -2     |\n",
    "| > 175              |   -1     |\n",
    "| > 200              |    0     |\n",
    "| > 225              |    1     |\n",
    "| > 250              |    2     |\n",
    "\n",
    "</td></tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "### Steigerung des Wertes eines Hauses\n",
    "Soll der Wert eines Hauses **schnell, einfach** und möglichst **ohne hohe zusätzliche Kosten** gesteigert werden, ist der folgende Tipp Gold wert:\n",
    "\n",
    "Die **Wertsteigerung** eines Hauses kann schnell und kostengünstig durch eine **Fassadenreinigung** erreicht werden. Dadurch wird die **Fassadenqualität** und der **Gesamteindruck** des Hauses **gesteigert**, welche einen starken Einfluss auf den Verkaufspreis des Hauses haben. Es sind keine nervigen und aufwändigen Umbauten erforderlich, die den Geldbeutel zusätzlich belasten. Brökelt die Fassade bereits ab, kann ein Maler hinzugezogen werden, der sich um die **Restaurierung** kümmert. Die Kosten eines Malers sind in den meisten Fällen geringer als der **Mehrwert**, der dadurch **generiert** wird. Die angesetzte Malerpauschale kann mit der Vorhersage des Hauspreises mit höherer Fassadenqualität gegengerechnet und verglichen werden. Dadurch kann herausgefunden werden, ob sich das Hinzuziehen eines Malers lohnt.\n",
    "\n",
    "### Wichtigste Erkenntnisse:\n",
    "Durch die Analyse konnten die Attribute bestimmt werden, welche den Verkaufspreis am meisten beeinflussen und oben aufgeführt sind. Grundlegend lässt sich bei Attributen, die eine Größe beschreiben (wie Wohnfläche_qm, EG_qm), sagen, dass ein **höherer Wert** für einen **höheren Preis** sorgt. Der Verkaufspreis wird ebenfalls stark von der Anzahl an Bädern, Kaminen und Garagen beeinflusst.\n",
    "\n",
    "Aus den Daten wurde ersichtlich, dass es heutzutage fast nur Flach- und Satteldächer gibt, wobei Häuser mit **modernen Flachdächern** mit einem Baujahr ab 2000 wesentlich **höhere Verkaufspreise** erzielen.\n",
    "\n",
    "Der Verkaufspreis nimmt mit steigendem Baujahr zu, da **neuere Häuser teurer** verkauft werden, dies wird jedoch für ältere Häuser durch einen **Umbau** ausgeglichen, was ihren **Wert** wieder deutlich **steigert**. Ein Haus, das **neu verkauft** wird, ist im Durchschnitt **teurer**, als ein Haus, das nicht neu verkauft wird. Der **Verkaufszeitpunkt** im Bezug auf den Monat scheint **wenig Einfluss** auf den Hauspreis zu haben, lediglich im **Januar** sind Verkaufspreise **marginal höher** als im restlichen Jahr. Muss ein Haus dringend verkauft werden, bieten sich die Frühlings- und Sommermonate an.\n",
    "\n",
    "Die Gegenden, in welchen die **teuersten Häuser** verkauft werden, sind **Neu Stuttgart (West und Süd)**. Beim Neubau eines Hauses könnte so der Preis durch geschickte Wahl des Bauortes wesentlich gesteigert werden. Sehr wahrscheinlich sind hier allerdings auch die Bauplätze teurer. \n",
    "\n",
    "### Augen auf beim Häuserkauf!\n",
    "\n",
    "Bei **Verhandlungsgesprächen** während des Hauskaufes wird üblicherweise versucht, das **Haus** zunächst **über** dem **Wert** anzubieten. Eventuell werden dafür Attribute des Hauses angepriesen, welche den vom Käufer wahrgenommenen Wert des Hauses steigern sollen, aber den **Hauspreis** fast **nicht beinflussen**. Solche Attribute könnten z.B. die **Kellerqualität**, der **Haustyp**, oder die **Anzahl der Zimmer** sein. Man kann pauschal nicht sagen, dass diese einen höheren Preis rechtfertigen."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add-On: Modeling - Klassifikation\n",
    "\n",
    "**Aufgabenstellung**: _Versuchen Sie eine Vorhersage der Kamine (ja / nein, alternativ: Anzahl der Kamine, Feld: Kamine). Evaluieren Sie die Vorhersage. Dieser Punkt fließt nicht in alle anderen Aufgabenteile ein._"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hier werden verschiedene Klassifikationsmethoden ausprobiert und schlussendlich mit einer **Receiver Operator Characteristic (ROC)-Kurve** verglichen. Dabei wird für jeden Klassifikator der Mittelwert von den fünf ROC Kurven einer 5-Fold CV gebildet. Es wird sich auf die **ja/nein-Vorhersage** der Kamine beschränkt. Die folgenden Klassifkatoren wurden für die Klassifikation ausgewählt und untersucht.\n",
    "\n",
    "- Logistische Regression\n",
    "- Gradient Boosted Trees\n",
    "- Random Forest\n",
    "- SVM\n",
    "- KNN\n",
    "- Naive Bayes"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Alle Datensätze von Häusern, welche mehr als 0 Kamine haben, werden auf True gesetzt, die Datensätze ohne Kamin auf False.\n",
    "x_class = train_data.drop(columns=[\"Kamine\"])\n",
    "y_class = train_data[\"Kamine\"].replace({0: False, 1: True, 2: True, 3: True, 4: True})"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funktion für die Berechnung von Klassifikationsmetriken mithilfe von 5 Fold CV"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def perform_classification(classifier, classifier_name):\n",
    "    \"\"\"\n",
    "\n",
    "    Diese Methode führt für einen gegebenen Klassifikator eine 5 Fold Crossvalidation durch.\n",
    "    Für jede Fold wird eine ROC Kurve und die AUC berechnet und ausgegeben.\n",
    "    Zusätzlich werden die True Positive Rate, die durchschnittlichen TPR und FPR \n",
    "    sowie die durschnittlichen AUC für den Klassifiktor berechnet.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # changed slighty based on: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-download-auto-examples-model-selection-plot-roc-crossval-py\n",
    "\n",
    "    # Create cross validation\n",
    "    cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "    # Abbreviations:\n",
    "    # - TPR: True positive rate\n",
    "    # - FPR: False positive rate\n",
    "    # - AUC: Area under curve\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    # Create the figure\n",
    "    _, axes = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    # Split the data into train and test for each split of the cross validation\n",
    "    for i, (train, test) in enumerate(cv.split(x_class, y_class)):\n",
    "        # Fit the data specified by the train-indexes to the given classifier\n",
    "        classifier.fit(x_class.iloc[train].values, y_class.iloc[train].values)\n",
    "\n",
    "        # Create the ROC curve\n",
    "        viz = RocCurveDisplay.from_estimator(\n",
    "            classifier,\n",
    "            x_class.iloc[test].values,\n",
    "            y_class.iloc[test].values,\n",
    "            name=\"ROC fold {}\".format(i),\n",
    "            alpha=0.3,\n",
    "            lw=1,\n",
    "            ax=axes\n",
    "        )\n",
    "\n",
    "        # Interpolate the tpr\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "\n",
    "        # Save true positive rate and area under curve\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    # Display a red line -> chance (50/50)\n",
    "    axes.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "    # Display the mean ROC curve\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    axes.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=f\"Mean ROC (AUC = {np.around(mean_auc, 2)} $\\pm$ {np.around(std_auc, 2)})\",\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # Slightly color the standard deviation\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    axes.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    # Set title and axis range\n",
    "    axes.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        title=f\"ROC für {classifier_name}\",\n",
    "    )\n",
    "    axes.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    # Return values needed for the comparison of the ROCs of each classifier\n",
    "    return mean_tpr, mean_fpr, mean_auc, std_auc, tprs"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Für jeden Klassifikator werden die Metriken Accuracy, Precision, Recall und der F1 Score berechnet."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "classification_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "def perform_cross_validation_classification(classifier, x=x_class, y=y_class):\n",
    "    \"\"\"\n",
    "    Diese Methode führt für einen gegebenen Klassifkator eine 5-Fold Crossvalidierung durch, und gibt die in \"classification_metrics\"\n",
    "    spezifizierten Metriken für jede Fold aus. Zusätzlich wird ein arithmetisches Mittel für jede Metrik gebildet.\n",
    "    \"\"\"\n",
    "\n",
    "    validation = cross_validate(classifier, x.values, y.values, cv=5, scoring=classification_metrics)\n",
    "\n",
    "    print(\"Cross-Validation:\")\n",
    "    for key, value in [item for item in validation.items() if \"time\" not in item[0]]:\n",
    "        print(f\"\\n  - {key.replace('test_', '')}:\")\n",
    "        for val in value:\n",
    "            print(f\"\\t{val}\")\n",
    "\n",
    "        print(f'\\n\\tmean: {np.around(np.mean(value), decimals=4)}, var: {np.around(np.var(value), decimals=4)}')"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistische Regression"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistische Regression\n",
    "logistic_classifier = LogisticRegression(random_state=0, max_iter=10000)\n",
    "logistic_values = perform_classification(logistic_classifier, \"Logistische Regression\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Ausgabe von Metriken nach 5-Fold CV\n",
    "perform_cross_validation_classification(logistic_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient Boosting Classifier"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# GradientBoosting Klassifikation\n",
    "gradient_classifier = GradientBoostingClassifier()\n",
    "gradient_values = perform_classification(gradient_classifier, \"Gradient Boosting\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "perform_cross_validation_classification(gradient_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest Classifier"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier Klassifikation\n",
    "forest_classifier = RandomForestClassifier()\n",
    "forest_values = perform_classification(forest_classifier, \"Random Forest\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "perform_cross_validation_classification(forest_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Support Vector Classification"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Support Vector Classification\n",
    "svc_classifier = SVC()\n",
    "svc_values = perform_classification(svc_classifier, \"Support Vector Classification\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Ausgabe von Metriken nach 5-Fold CV\n",
    "perform_cross_validation_classification(svc_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### K Nearest Neighbours"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN Classification\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_values = perform_classification(knn_classifier, \"K Nearest Neighbours\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "perform_cross_validation_classification(knn_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naives Bayes Classificator"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "bayes_classifier = GaussianNB()\n",
    "bayes_values = perform_classification(bayes_classifier, \"Naive Bayes\")"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "perform_cross_validation_classification(bayes_classifier)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vergleich der Klassifikationsmethoden\n",
    "Hier werden die gemittelten ROC Kurven der Klassifikatoren nebeneinander aufgetragen und verglichen. Ein wichtiges Merkmal dafür ist die sog. AUC (Area under Curve)"
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def show_mean_roc(plt_axes, classifier_values, classifier_name, classifier_color):\n",
    "    \"\"\"\n",
    "    Zeige die gemittelten ROC Kurve für eine Klassifikator an, zusammen mit dem AUC.\n",
    "    \"\"\"\n",
    "\n",
    "    plt_axes.plot(\n",
    "        classifier_values[1],\n",
    "        classifier_values[0],\n",
    "        color=classifier_color,\n",
    "        label=f\"{classifier_name} Mean ROC (AUC {np.around(classifier_values[2], 2)} $\\pm$ {np.around(classifier_values[3], 2)})\",\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # Standardabweichung von Mean einfärben --> zu unübersichtlich, daher auskommentiert\n",
    "    #std_tpr = np.std(classifier_values[4], axis=0)\n",
    "    #plt_axes.fill_between(\n",
    "    #    classifier_values[1],\n",
    "    #    np.maximum(classifier_values[0] - std_tpr, 0),\n",
    "    #    np.minimum(classifier_values[0] + std_tpr, 1),\n",
    "    #    color=classifier_color,\n",
    "    #    alpha=0.2,\n",
    "    #    label=f\"{classifier_name} $\\pm$ 1 std. dev.\",\n",
    "    #)"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Ausgabe der gemittelten ROC Kurven für alle Klassifikatoren zusammen mit dem AUC\n",
    "\n",
    "_, axes = plt.subplots(figsize=(20, 10))\n",
    "axes.set_title(\"Vergleich der durchschnittlichen ROCs der einzelnen Klassifier\")\n",
    "axes.set_xlabel(\"Falsch-Positiv Rate\")\n",
    "axes.set_ylabel(\"Richtig-Positiv Rate\")\n",
    "\n",
    "show_mean_roc(axes, logistic_values, \"Logistic Regression\", \"b\")\n",
    "show_mean_roc(axes, gradient_values, \"Gradient Boosting\", \"r\")\n",
    "show_mean_roc(axes, forest_values, \"Random Forest\", \"g\")\n",
    "show_mean_roc(axes, svc_values, \"Support Vector\", \"grey\")\n",
    "show_mean_roc(axes, knn_values, \"K Nearest Neighbour\", \"black\")\n",
    "show_mean_roc(axes, bayes_values, \"Naive Bayes\", \"pink\")\n",
    "\n",
    "axes.set(\n",
    "    xlim=[-0.05, 1.05],\n",
    "    ylim=[-0.05, 1.05],\n",
    ")\n",
    "\n",
    "# Einzeichnen der ROC Kurve eines zufälligen Klassifikators\n",
    "axes.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "axes.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation\n",
    "\n",
    "Für alle ausgewählten Klassifikatoren wurde jeweils die **ROC-Kurve** gezeichnet. Ihre Güte kann z.B. mittels der **AUC (Area under Curve)** bewertet werden. Die beiden Klassifikatoren mit der **höchsten AUC** sind **Gradient Boosted Tree** und **Random Forest** mit 0.88 +- 0.02. Es ergeben sich die folgenden **F1-Scores**:\n",
    "\n",
    "| **Klassifikator**    | **F1-Score** |\n",
    "|----------------------|:------------:|\n",
    "|Gradient Boosted Tree |0.8059        |\n",
    "|Random Forest         |0.8038        |\n",
    "\n",
    "Vergleicht man die Klassifikatoren nach dem F1 Score, so ist der Gradient Boosted Tree Klassifikator marginal besser."
   ],
   "attachments": {},
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bewertungskriterien\n",
    "\n",
    "1. Fachliche Bewertung (50%): Korrektheit, Lösungsqualität und Eleganz sowie Klarheit und Umfang der Betrachtung, Umsetzung von Data Science wie in der Vorlesung gelehrt in einem Code-Prototyp, korrekte Verwendung von wichtigen Funktionen / Bibliotheken, Güte der Endlösung, Nutzung der erworbenen Kenntnisse aus der Vorlesung, Vollständigkeit der Lösung in Bezug auf die Aufgabenstellung\n",
    "2. Dokumentation (50%): Dokumentation des Vorgehens der Datenauswertung im Sinne von Data Science, Codekommentare wie in der Informatik üblich wo notwendig, Qualität der Diagramme, Markup, Texte, pdf"
   ],
   "attachments": {},
   "metadata": {}
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}